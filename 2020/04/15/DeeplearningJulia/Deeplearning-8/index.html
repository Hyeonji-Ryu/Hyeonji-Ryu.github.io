<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://hyeonji-ryu.github.io').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.1',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="해당 시리즈는 프로그래밍 언어 중 하나인 줄리아(Julia)로 딥러닝(Deep learning)을 구현하면서 원리를 설명합니다.">
<meta property="og:type" content="article">
<meta property="og:title" content="8. 인공신경망 구현 - 역전파 설명">
<meta property="og:url" content="https://hyeonji-ryu.github.io/2020/04/15/DeeplearningJulia/Deeplearning-8/index.html">
<meta property="og:site_name" content="DEV AnythinG">
<meta property="og:description" content="해당 시리즈는 프로그래밍 언어 중 하나인 줄리아(Julia)로 딥러닝(Deep learning)을 구현하면서 원리를 설명합니다.">
<meta property="og:locale" content="ko_KR">
<meta property="og:image" content="https://hyeonji-ryu.github.io/images/43.png">
<meta property="og:image" content="https://hyeonji-ryu.github.io/images/44.png">
<meta property="og:image" content="https://hyeonji-ryu.github.io/images/51.png">
<meta property="article:published_time" content="2020-04-15T13:56:01.000Z">
<meta property="article:modified_time" content="2020-06-19T05:01:35.545Z">
<meta property="article:author" content="Hyeonji Ryu">
<meta property="article:tag" content="딥러닝">
<meta property="article:tag" content="Deeplearning">
<meta property="article:tag" content="머신러닝">
<meta property="article:tag" content="줄리아">
<meta property="article:tag" content="신경망">
<meta property="article:tag" content="역전파">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hyeonji-ryu.github.io/images/43.png">

<link rel="canonical" href="https://hyeonji-ryu.github.io/2020/04/15/DeeplearningJulia/Deeplearning-8/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>8. 인공신경망 구현 - 역전파 설명 | DEV AnythinG</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-163411677-2"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-163411677-2');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">DEV AnythinG</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Welcome :)</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>홈</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>태그</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>카테고리</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>아카이브</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>검색
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/Hyeonji-Ryu" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="ko">
    <link itemprop="mainEntityOfPage" href="https://hyeonji-ryu.github.io/2020/04/15/DeeplearningJulia/Deeplearning-8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/profile.jpg">
      <meta itemprop="name" content="Hyeonji Ryu">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="DEV AnythinG">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          8. 인공신경망 구현 - 역전파 설명
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">작성일</span>

              <time title="Post created: 2020-04-15 22:56:01" itemprop="dateCreated datePublished" datetime="2020-04-15T22:56:01+09:00">2020-04-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-learning-in-Julia/" itemprop="url" rel="index">
                    <span itemprop="name">Deep learning in Julia</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>해당 시리즈는 프로그래밍 언어 중 하나인 줄리아(Julia)로 딥러닝(Deep learning)을 구현하면서 원리를 설명합니다.<br><a id="more"></a></p>
<hr>
<p>이전 글에서는 왼쪽 방향에서 오른쪽 방향으로 이동하는 미분법인 순전파 알고리즘을 살펴보았다. 순전파 알고리즘은 학습을 진행할 때마다 각각 매개변수의 미분값을 구해야 하기 때문에 신경망 계산이 매개변수 개수의 두 배가 진행된다. 이전 글에서의 신경망 모델을 예시로 보면 가중치와 편향이 총 4개이기 때문에 순전파 기반으로 학습을 한 번 할 때마다 신경망 계산은 총 8번 이루어진다. 이 방식은 매우 비효율적이고 시간이 오래걸린다. 순전파보다 더 효율적으로 미분하는 방법이 바로 역전파 알고리즘이다. 이번 장에서는 역전파 알고리즘에 대해서 살펴볼 것이다.</p>
<h2 id="역전파란"><a href="#역전파란" class="headerlink" title="역전파란"></a>역전파란</h2><p>역전파(backward propagation)는 순전파와 다르게 미분을 반대로 하는 것을 의미한다. 즉, 순전파는 왼쪽에서 오른쪽 방향으로 미분이 이루어진다면, 역전파는 오른쪽에서 왼쪽 방향으로 미분이 이루어진다. 도식에서 확인하자면 아래와 같다.</p>
<p><img src="\../images/43.png" alt="신경망 계산 방향"></p>
<p>또한 순전파와 역전파는 신경망 계산이 이루어지는 과정도 약간 다르다. 우리가 만든 2층 신경망 모델의 순전파 알고리즘은 각각 가중치와 편향의 편미분 값을 구하기 위해서 신경망 계산이 8번 이루어지지만, 역전파 알고리즘은 한번 진행될 때 가중치와 편향의 편미분 값을 바로 구할 수 있다. 이것이 역전파가 순전파보다 훨씬 빠르게 진행되는 이유이다. 신경망 계산은 행렬 계산으로 이루어지기 때문에 매우 복잡하고 계산량이 많다. 따라서 계산을 여러 번 할수록 훨씬 많은 시간이 소요된다. 따라서 시간의 관점에서 역전파는 순전파보다 훨씬 더 효율적인 알고리즘이라고 볼 수 있다. 순전파와 역전파의 차이를 정리하면 다음과 같다.</p>
<p><img src="\../images/44.png" alt="미분 알고리즘 비교"></p>
<h2 id="역전파의-원리-합성함수의-미분"><a href="#역전파의-원리-합성함수의-미분" class="headerlink" title="역전파의 원리: 합성함수의 미분"></a>역전파의 원리: 합성함수의 미분</h2><p>역전파가 한번에 편미분을 구할 수 있는 원리는 합성함수의 미분을 이용한 것이다. 먼저 우리가 만들었던 2층 신경망 모델의 수식을 확인해보자.</p>
<script type="math/tex; mode=display">\hat{y}=\sigma(h(XW1+B1)\times W2+B2)</script><p>위의 수식을 다음과 같이 정리할 수 있다.</p>
<script type="math/tex; mode=display">Z1=XW1+B1\\
 A1 = h(Z1)\\
Z2=A1W2+B2\\
\sigma(Z2) = \hat{y}</script><p>위 수식은 신경망 계산 순서를 그대로 나열한 것이다. 순전파 알고리즘에서는 각각 매개변수를 편미분하여 예측값을 비교한다. 하지만 역전파 알고리즘은 위의 수식들을 미분한 식을 바탕으로 기존 매개변수들을 받아 각 매개변수들의 미분값을 한번에 계산한다.</p>
<p>즉, 역전파 알고리즘은 다음과 같다.</p>
<script type="math/tex; mode=display">\partial\hat{y} =
\partial\sigma(Z2)\\
\partial Z2= \partial(A1W2 + B2)\\
\partial A1 = \partial h(Z1)\\
\partial Z1 = \partial(XW1+B1)</script><p>위 순서는 합성함수의 미분이다. 합성함수는 변수가 두개 이상의 함수에 둘러싸인 경우를 의미한다. 예시로 아래의 사례를 보자.</p>
<script type="math/tex; mode=display">y = t^2 , t = x+2</script><p>위의 식 $y$에서 $x$를 미분하기 위해서는 중간의 $t$를 미분해야 한다. 따라서 다음과 같은 방법으로 미분된다.</p>
<script type="math/tex; mode=display">\frac{dy}{dx}= \frac{dy}{dt} \cdot \frac{dt}{dx}</script><p>위의 미분식에서 $dt$는 약분되기 때문에 결국 $\frac{dy}{dx}$가 남는 것이다. 이를 정리하면 다음과 같다.</p>
<script type="math/tex; mode=display">\begin{matrix}
\frac{\partial y}{\partial x}& = & \partial (t^2) \times \partial t\\
&=& 2t \times \partial (x+2) \\
&=& 2(x+2) \times 1 \\
&=& 2x+4\\
\end{matrix}</script><p>이 방식을 2층 신경망 역전파 알고리즘에 대입하여 미분식을 구할 수 있다. 미분식은 아래와 같다.</p>
<script type="math/tex; mode=display">\begin{matrix}
\frac{\partial \hat{y}}{\partial W1}& = & \frac{\partial \hat{y}}{\partial Z2} &\times& \frac{\partial Z2}{\partial A1} &\times& \frac{\partial A1}{\partial Z1} &\times& \frac{\partial Z1}{\partial W1}\\
&&\\
\frac{\partial \hat{y}}{\partial W2}& = & \frac{\partial \hat{y}}{\partial Z2} &\times& \frac{\partial Z2}{\partial W2}\\
&&\\
\frac{\partial \hat{y}}{\partial b1}& = & \frac{\partial \hat{y}}{\partial Z2} &\times& \frac{\partial Z2}{\partial A1} &\times& \frac{\partial A1}{\partial Z1} &\times& \frac{\partial Z1}{\partial b1}\\
&&\\
\frac{\partial \hat{y}}{\partial b2}& = & \frac{\partial \hat{y}}{\partial Z2} &\times& \frac{\partial Z2}{\partial b2}\\
\end{matrix}</script><p>위의 공식을 비교해보면 각각 매개 변수에 동일하게 적용되는 미분이 있을 것이다. 이를 알고리즘으로 구현하여 좀 더 빠르게 미분값을 구할 수 있도록 고안한 것이 역전파 알고리즘이다.</p>
<h2 id="역전파-알고리즘-미분-과정"><a href="#역전파-알고리즘-미분-과정" class="headerlink" title="역전파 알고리즘 미분 과정"></a>역전파 알고리즘 미분 과정</h2><p><img src="\../images/51.png" alt="역전파 알고리즘"></p>
<p>2층 신경망 역전파 알고리즘은 위와 같은 구조로 이루어져 있다. 우리는 위의 역전파 알고리즘에서 각 층을 함수로 구현할 것이다. 참고로 아래의 수식에서 사용되는 대문자는 행렬이며, 소문자는 스칼라이다. 특히 $Z_n$과 같은 기호는 행렬 $Z$의 $n$(인덱스)위치에 속해있는 요소를 가리킨다.</p>
<h3 id="Softmax-with-Loss-Layer"><a href="#Softmax-with-Loss-Layer" class="headerlink" title="Softmax with Loss Layer"></a>Softmax with Loss Layer</h3><p>역전파 알고리즘에서는 출력층에서 사용되는 소프트맥스 함수와 손실 함수인 교차 엔트로피 오차 수식을 같이 미분한다. 그 이유는 두 함수를 동시에 미분한 결과가 훨씬 간단하기 떄문이다. 역전파의 미분은 손실 함수인 교차 엔트로피 오차 수식 미분을 먼저 진행하고 그다음 소프트맥스 함수를 미분하여 결과를 도출할 것이다.</p>
<ul>
<li><p>교차 엔트로피 오차 수식 미분</p>
<script type="math/tex; mode=display">L = -\sum_{n} T_n \ln Y_n</script><p>위 식은 교차 엔트로피 오차이이며, $T$는 정답레이블, $Y$는 예측값, $n$은 신경망 노드의 개수를 의미한다. 즉, 소프트맥스 함수에서 예측값이 $[y_1, y_2, y_3]$로 왔다면 $n$은 3이다. 위 식을 미분하면 다음과 같은 결과를 얻을 수 있다.</p>
<script type="math/tex; mode=display">\partial L = -\sum_{n} \frac{T_n}{Y_n}</script><p>위의 식에서 $-\frac{1}{Y_n}$가 각각의 소프트맥스 함수의 신경망으로 전달된다. 예를 들어 소프트맥스 함수의 결과값이 총 3개가 들어왔다면 $-\frac{T_1}{Y_1}, -\frac{T_2}{Y_2}, -\frac{T_3}{Y_3}$이 소프트맥스 미분식의 입력값으로 들어간다.</p>
</li>
<li><p>소프트맥스 함수 미분</p>
<script type="math/tex; mode=display">\sigma(Z_k)=\frac{e^{Z_k}}{\sum_{i=n}^n e^{Z_n}}</script><p>위 수식은 소프트맥스 함수이다. 위의 교차 엔트로피 오차와 마찬가지로 $n$은 신경망 노드 개수이다. 즉, 입력값이 $[z_1, z_2, z_3]$이라면 $n$은 3이고, $k$는 $1,2,3$ 중에 하나이다. 이를 미분하면 다음과 같은 결과를 얻을 수 있다.</p>
<p>1) 소프트맥스의 입력값과 편미분 대상이 동일할 때 (둘 다 $Z_k$)</p>
<script type="math/tex; mode=display">\frac{\partial\sigma(Z_k)}{\partial Z_k} = \frac{e^{Z_k}(\sum_{i} e^{Z_i})-e^{Z_k}e^{Z_k}}{(\sum_{i} e^{Z_i})^2}</script><script type="math/tex; mode=display">\quad \quad \quad \ = \frac{e^{Z_k}\{(\sum_{i} e^{Z_i})-e^{Z_k}\}}{(\sum_{i} e^{Z_i})^2}</script><script type="math/tex; mode=display">\quad \quad \quad \quad = \frac{e^{Z_k}}{\sum_{i} e^{Z_i}} \frac{(\sum_{i} e^{Z_i})-e^{Z_k}}{\sum_{i} e^{Z_i}}</script><script type="math/tex; mode=display">\quad \quad \quad \quad = \frac{e^{Z_k}}{\sum_{i} e^{Z_i}}\Bigg(1-\frac{e^{Z_k}}{\sum_{i} e^{Z_i}}\Bigg)</script><script type="math/tex; mode=display">\quad \quad  = \sigma(Z_k)(1-\sigma(Z_k))</script><p>2) 소프트맥스의 입력값과 편미분 대상이 다를 때 ($Z_k$와 $Z_j$)</p>
<script type="math/tex; mode=display">\frac{\partial\sigma(Z_j)}{\partial Z_k} = \frac{0-e^{Z_k}e^{Z_j}}{(\sum_{i=1} e^{Z_i})^2}</script><script type="math/tex; mode=display">\quad \quad \quad \quad \quad \quad \quad = -\frac{e^{Z_k}}{\sum_{i=1} e^{Z_i}} \frac{e^{Z_j}}{\sum_{i=1} e^{Z_i}}</script><script type="math/tex; mode=display">\quad \quad \quad \quad = -\sigma(Z_k)\sigma(Z_j)</script></li>
</ul>
<p>소프트맥스 함수는 미분될 때 동일한 변수와 동일하지 않은 변수를 모두 미분해야 한다. 그 이유는 손실 함수에서 $n$개의 변수를 미분하는데 $n$에는 편미분 변수인 $k$도 들어가지만 편미분 변수가 아닌 $j$도 포함되기 때문이다.</p>
<p>위의 미분식들을 활용하여 역전파 알고리즘에 사용되는 함수를 정리해보자.</p>
<script type="math/tex; mode=display">\frac{\partial L}{\partial Z_k} = \frac{\partial L}{\partial \sigma(Z_n)}\frac{\partial\sigma(Z_n)}{\partial Z_k}</script><script type="math/tex; mode=display">\quad \quad \ \ =-\sum_{n}\frac{Y_n}{Z_n}\frac{\partial\sigma(Z_n)}{\partial Z_k}</script><p>$\frac{\partial\sigma(Z_n)}{\partial Z_k}$은 $k$에 대한 미분과 $j$에 대한 미분을 모두 포함한다. 따라서 분리하여 미분을 진행한다.</p>
<script type="math/tex; mode=display">\quad \quad \quad =-\frac{Y_k}{Z_k}Z_k(1-Z_k)-\sum_{n \ne k}\frac{Y_n}{Z_n}(-Z_kZ_n)</script><script type="math/tex; mode=display">=-Y_k(1-Z_k)-\sum_{n \ne k}-Y_nZ_k</script><script type="math/tex; mode=display">=-Y_k+Y_kZ_k+\sum_{n \ne k}Y_nZ_k</script><script type="math/tex; mode=display">=-Y_k+Z_k\sum_{n}Y_n</script><p>여기서 $\sum_{n}Y_n$는 기존 소프트맥스 확률의 합이기 때문에 1이 된다.</p>
<script type="math/tex; mode=display">=-Y_k+Z_k \times 1</script><script type="math/tex; mode=display">=Z_k-Y_k</script><p>결론적으로 ‘Softmax with Loss’는 위와 같은 간단한 수식이다. 어차피 우리는 결론인 위의 간단한 수식만 사용할 것이기 때문에 만약 위의 수식들이 어렵다면 결론만 봐도 무방하다.</p>
<h3 id="Dense-Layer"><a href="#Dense-Layer" class="headerlink" title="Dense Layer"></a>Dense Layer</h3><p>‘Dense Layer’는 들어온 입력값에 가중치를 곱하고 편향을 더하는 방정식이다. 수식으로 쓰면 아래와 같다.</p>
<script type="math/tex; mode=display">Z=XW+B</script><p>위 수식을 미분해보자. 참고로 Dense Layer에서 사용되는 모든 변수들은 행렬을 기본으로 하고 있다. 즉, $XW$은 행렬곱이다. 그렇다면 행렬곱은 어떻게 미분되는가?<br>기본적으로 신경망에서 사용되는 행렬은 벡터 단위이다. 즉, 행렬도 벡터가 여러 개 합쳐져 있는 형태로 바라본다는 것이다.</p>
<p>미분을 이해하기 위해서 간단하게 예시를 보자.</p>
<p>입력값인 행렬 $X$와 가중치인 행렬 $W$를 다음과 같이 설정한다. 벡터는 열벡터 형태가 기본이기 때문에 아래의 행렬은 벡터 별 색깔을 다르게 설정하였다.</p>
<script type="math/tex; mode=display">\begin{matrix}
\quad \quad X_1 & X_2 &&&& W_1 & W_2 &W_3
\end{matrix}</script><script type="math/tex; mode=display">X=\begin{bmatrix}
\color{ForestGreen}{x_{11}} &\color{LimeGreen}{x_{12}}\\
\color{ForestGreen}{x_{21}} & \color{LimeGreen}{x_{22}}
\end{bmatrix}

W=\begin{bmatrix}
\color{OrangeRed}{w_{11}} & \color{Orange}{w_{12}} & \color{Salmon}{w_{13}}\\
\color{OrangeRed}{w_{21}} & \color{Orange}{w_{22}} & \color{Salmon}{w_{23}}
\end{bmatrix}</script><p>두 행렬을 곱할 때는 열 단위로 내적되는 것이 아니라 X가 행벡터로 변환되어 내적된다. 즉, 수식으로 표현하면 다음과 같다.</p>
<script type="math/tex; mode=display">X \cdot W = X^TW</script><p>따라서 $X \cdot W$인 식이 결과값 $Y$라고 했을 때, $Y$는 다음과 같다.</p>
<script type="math/tex; mode=display">Y=\begin{bmatrix}
\color{ForestGreen}{x_{11}}\color{OrangeRed}{w_{11}}+ \color{ForestGreen}{x_{21}}\color{OrangeRed}{w_{21}}& \color{ForestGreen}{x_{11}}\color{Orange}{w_{12}} +\color{ForestGreen}{x_{21}}\color{Orange}{w_{22}}& \color{ForestGreen}{x_{11}}\color{Salmon}{w_{13}}+\color{ForestGreen}{x_{21}}\color{Salmon}{w_{23}}\\
\color{LimeGreen}{x_{12}}\color{OrangeRed}{w_{11}}+ \color{LimeGreen}{x_{22}}\color{OrangeRed}{w_{21}}& \color{LimeGreen}{x_{12}}\color{Orange}{w_{12}}+ \color{LimeGreen}{x_{22}}\color{Orange}{w_{22}}& \color{LimeGreen}{x_{12}}\color{Salmon}{w_{13}}+\color{LimeGreen}{x_{22}}\color{Salmon}{w_{23}}
\end{bmatrix}</script><p>위의 행렬을 벡터의 곱으로 표현해보자.</p>
<script type="math/tex; mode=display">Y=\begin{bmatrix}
X_1W_1 & X_1W_2 & X_1W_3\\
X_2W_1 & X_2W_2 & X_2W_3\\
\end{bmatrix}</script><p>위 식은 행렬 $W$가 행렬 $X^T$와 곱한 형태라는 것을 증명한다. 위의 행렬을 $W_1~ or~ W_2~ or~ W_3$로 각각 미분해도 결과는 동일하다.</p>
<script type="math/tex; mode=display">\frac{\partial Y}{\partial W} =
\begin{bmatrix}
X_1\\
X_2\\
\end{bmatrix}</script><p>이를 행렬로 풀면 다음과 같다.</p>
<script type="math/tex; mode=display">\frac{\partial Y}{\partial W} =
\begin{bmatrix}
\color{ForestGreen}{x_{11}} &\color{ForestGreen} {x_{21}}\\
\color{LimeGreen}{x_{12}} & \color{LimeGreen}{x_{22}}\\
\end{bmatrix}
=
X^T</script><p>위와 같은 원리로 다음과 같은 결론을 낼 수 있다.</p>
<script type="math/tex; mode=display">\frac{\partial Y}{\partial W} = X^T</script><script type="math/tex; mode=display">\frac{\partial Y}{\partial X} = W^T</script><p>우리는 역전파 알고리즘에서 입력값과 가중치의 미분값으로 위의 식을 사용할 것이다.</p>
<p>편향의 경우, 신경망 계산 시에 모든 원소에 더해지기 때문에 미분값을 열 기준으로 전부 더하면 된다.</p>
<h3 id="Sigmoid-Layer"><a href="#Sigmoid-Layer" class="headerlink" title="Sigmoid Layer"></a>Sigmoid Layer</h3><p>시그모이드 함수의 미분은 간단하다. 아래의 식을 확인하자.</p>
<script type="math/tex; mode=display">\frac{\partial h(Z_k)}{\partial Z_k} = \frac{0\times(1+e^{-Z_k})-1\times (0+e^{(-Z_k)})(-1) }{(1+e^{-Z_k})^2}</script><script type="math/tex; mode=display">\quad =\frac{e^{(-Z_k)}}{(1+e^{-Z_k})^2}= \frac{1+e^{(-Z_k)}-1}{(1+e^{-Z_k})^2}</script><script type="math/tex; mode=display">=\frac{(1+e^{(-Z_k)})}{(1+e^{-Z_k})^2}-\frac{1}{(1+e^{-Z_k})^2}</script><script type="math/tex; mode=display">= \frac{1}{(1+e^{-Z_k})}-\frac{1}{(1+e^{-Z_k})^2}</script><script type="math/tex; mode=display">\quad = \frac{1}{(1+e^{-Z_k})}\Big(1-\frac{1}{(1+e^{-Z_k})}\Big)</script><script type="math/tex; mode=display">= h(Z_k)(1-h(Z_k))</script><p>시그모이드 함수를 미분하여 정리하면 $h(Z_k)(1-h(Z_k))$ 이 도출된다. 따라서 역전파 알고리즘에 사용되는 시그모이드 함수는 위의 수식을 사용하여 구현될 것이다.</p>
<h3 id="ReLU-Layer"><a href="#ReLU-Layer" class="headerlink" title="ReLU Layer"></a>ReLU Layer</h3><p>ReLU 함수는 입력값 $x$가 음수인 경우만 0으로 변경하고 그대로 출력한다. 이를 수식으로 표현하면 다음과 같다.</p>
<script type="math/tex; mode=display">
y =
 \begin{cases}
0 & \text{(x≤0)$$}\\
x & \text{(x>0) $$}\\
\end{cases}</script><p>위 수식을 입력값 $x$로 미분하면 아래와 같은 결과가 도출된다.</p>
<script type="math/tex; mode=display">
\frac{\partial y}{\partial x} =
 \begin{cases}
0 & \text{(x≤0)$$}\\
1 & \text{(x>0) $$}\\
\end{cases}</script><p>따라서 역전파 알고리즘에서 Relu 함수는 입력값 $x$가 0보다 같거나 작으면 미분값에 0을 곱해서 출력하고, $x$보다 크면 1을 곱해서 출력한다. 그렇기 때문에 입력값에서 음수의 위치를 저장해두어야 한다.</p>
<h2 id="순전파-vs-역전파"><a href="#순전파-vs-역전파" class="headerlink" title="순전파 vs. 역전파"></a>순전파 vs. 역전파</h2><p>다음 글에서 살펴볼 역전파 알고리즘이 과연 잘 구현되었는지 확인해보자. 먼저 훈련데이터 이미지 3개를 <code>x_batch</code>와  <code>t_batch</code>에 할당한다. (참고로 사용된 훈련데이터는 MNIST 데이터이며, <a href="https://hyeonji-ryu.github.io/2020/04/04/Deeplearning-7/">이전 글</a>에서 가져오는 방법을 볼 수 있다.)</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_batch = train_x[<span class="number">1</span>:<span class="number">3</span>, :]</span><br><span class="line">t_batch = t[<span class="number">1</span>:<span class="number">3</span>, :]</span><br></pre></td></tr></table></figure>
<p>그 다음 순전파 알고리즘을 먼저 작동해보자.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TwoLayerNet_numerical_gradient(loss, x_batch, t_batch)</span><br></pre></td></tr></table></figure>
<p>위 코드를 실행하면 순전파 알고리즘으로부터 도출된 미분값을 얻을 수 있다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">grad_forward_W1 = grads[<span class="string">"W1"</span>]</span><br><span class="line">grad_forward_b1 = grads[<span class="string">"b1"</span>]</span><br><span class="line">grad_forward_W2 = grads[<span class="string">"W2"</span>]</span><br><span class="line">grad_forward_b2 = grads[<span class="string">"b2"</span>]</span><br></pre></td></tr></table></figure>
<p>위 코드를 입력하여 미분값을 저장하자. 이제 역전파 알고리즘을 사용하여 매개 변수의 미분값을 얻으려 한다. 역전파 알고리즘은 아직 살펴보지 못했기에 그 결과를 아래의 식에 도입해서 확인해보자.</p>
<script type="math/tex; mode=display">Difference = \frac{\sum{|forward~gradient - backward~gradient|}}{the~number~of~elements~in~Matrix}</script><p>위 식을 코드로 구현하면 아래와 같다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Julia&gt; diffW1 = sum((abs.(grad_forward_W1-grad_backward_W1))) / (size(grad_backward_W1)[<span class="number">1</span>]*size(grad_backward_W1)[<span class="number">2</span>])</span><br><span class="line">Julia&gt; diffW2 = sum((abs.(grad_forward_W2-grad_backward_W2))) / (size(grad_backward_W2)[<span class="number">1</span>]*size(grad_backward_W2)[<span class="number">2</span>])</span><br><span class="line">Julia&gt; diffb1 = sum((abs.(grad_forward_b1-grad_backward_b1))) / (size(grad_backward_b1)[<span class="number">1</span>]*size(grad_backward_b1)[<span class="number">2</span>])</span><br><span class="line">Julia&gt; diffb2 = sum((abs.(grad_forward_b2-grad_backward_b2))) / (size(grad_backward_b2)[<span class="number">1</span>]*size(grad_backward_b2)[<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<p>위 코드는 다음 글에서 역전파 알고리즘을 구현한 후 작동할 것이다. 결과는 다음과 같다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Julia&gt; diffW1</span><br><span class="line"> <span class="number">1.9589789748798898e-10</span></span><br><span class="line">Julia&gt; diffW2</span><br><span class="line"> <span class="number">7.040410144965037e-8</span></span><br><span class="line">Julia&gt; diffb1</span><br><span class="line"> <span class="number">8.881836618344343e-10</span></span><br><span class="line">Julia&gt; diffb2</span><br><span class="line"> <span class="number">1.394640827490079e-7</span></span><br></pre></td></tr></table></figure>
<p>순전파와 역전파 알고리즘으로 도출된 미분값들의 차이가 매우 작은 것을 확인할 수 있다. 즉, 역전파가 잘 구현되었다는 것이다. 그렇다면 역전파는 어떻게 줄리아로 구현하였을까? 다음 글에서 확인해보자.</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/" rel="tag"># 딥러닝</a>
              <a href="/tags/Deeplearning/" rel="tag"># Deeplearning</a>
              <a href="/tags/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/" rel="tag"># 머신러닝</a>
              <a href="/tags/%EC%A4%84%EB%A6%AC%EC%95%84/" rel="tag"># 줄리아</a>
              <a href="/tags/%EC%8B%A0%EA%B2%BD%EB%A7%9D/" rel="tag"># 신경망</a>
              <a href="/tags/%EC%97%AD%EC%A0%84%ED%8C%8C/" rel="tag"># 역전파</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/04/14/Mathematic/mathematic-2/" rel="prev" title="1. Linear Algebra (2)">
      <i class="fa fa-chevron-left"></i> 1. Linear Algebra (2)
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/04/20/AboutHexo/about-hexo-2/" rel="next" title="2. 카테고리 및 태그 설정">
      2. 카테고리 및 태그 설정 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          목차
        </li>
        <li class="sidebar-nav-overview">
          훑어보기
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#역전파란"><span class="nav-number">1.</span> <span class="nav-text">역전파란</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#역전파의-원리-합성함수의-미분"><span class="nav-number">2.</span> <span class="nav-text">역전파의 원리: 합성함수의 미분</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#역전파-알고리즘-미분-과정"><span class="nav-number">3.</span> <span class="nav-text">역전파 알고리즘 미분 과정</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Softmax-with-Loss-Layer"><span class="nav-number">3.1.</span> <span class="nav-text">Softmax with Loss Layer</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dense-Layer"><span class="nav-number">3.2.</span> <span class="nav-text">Dense Layer</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sigmoid-Layer"><span class="nav-number">3.3.</span> <span class="nav-text">Sigmoid Layer</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ReLU-Layer"><span class="nav-number">3.4.</span> <span class="nav-text">ReLU Layer</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#순전파-vs-역전파"><span class="nav-number">4.</span> <span class="nav-text">순전파 vs. 역전파</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hyeonji Ryu"
      src="/images/profile.jpg">
  <p class="site-author-name" itemprop="name">Hyeonji Ryu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">81</span>
          <span class="site-state-item-name">포스트</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">카테고리</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">179</span>
        <span class="site-state-item-name">태그</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hyeonji Ryu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.1
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.1
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
