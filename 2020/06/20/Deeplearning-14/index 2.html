<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://hyeonji-ryu.github.io').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.1',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="해당 시리즈는 프로그래밍 언어 중 하나인 줄리아(Julia)로 딥러닝(Deep learning)을 구현하면서 원리를 설명합니다.">
<meta property="og:type" content="article">
<meta property="og:title" content="14. CNN 시작하기">
<meta property="og:url" content="https://hyeonji-ryu.github.io/2020/06/20/Deeplearning-14/index.html">
<meta property="og:site_name" content="AI &amp; ML">
<meta property="og:description" content="해당 시리즈는 프로그래밍 언어 중 하나인 줄리아(Julia)로 딥러닝(Deep learning)을 구현하면서 원리를 설명합니다.">
<meta property="og:locale" content="ko_KR">
<meta property="og:image" content="https://hyeonji-ryu.github.io/images/65.png">
<meta property="og:image" content="https://hyeonji-ryu.github.io/images/66.png">
<meta property="og:image" content="https://hyeonji-ryu.github.io/images/67.png">
<meta property="og:image" content="https://hyeonji-ryu.github.io/images/68.png">
<meta property="article:published_time" content="2020-06-20T06:04:49.000Z">
<meta property="article:modified_time" content="2020-07-16T18:28:42.805Z">
<meta property="article:author" content="Hyeonji Ryu">
<meta property="article:tag" content="딥러닝">
<meta property="article:tag" content="Deeplearning">
<meta property="article:tag" content="줄리아">
<meta property="article:tag" content="CNN">
<meta property="article:tag" content="합성곱">
<meta property="article:tag" content="이미지신경망">
<meta property="article:tag" content="풀링">
<meta property="article:tag" content="Julia">
<meta property="article:tag" content="모델">
<meta property="article:tag" content="flatten">
<meta property="article:tag" content="convolution">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hyeonji-ryu.github.io/images/65.png">

<link rel="canonical" href="https://hyeonji-ryu.github.io/2020/06/20/Deeplearning-14/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>14. CNN 시작하기 | AI & ML</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-163411677-2"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-163411677-2');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">AI & ML</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Julia, Python, R</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>홈</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>태그</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>카테고리</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>아카이브</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>검색
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/Hyeonji-Ryu" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="ko">
    <link itemprop="mainEntityOfPage" href="https://hyeonji-ryu.github.io/2020/06/20/Deeplearning-14/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Hyeonji Ryu">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AI & ML">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          14. CNN 시작하기
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">작성일</span>

              <time title="Post created: 2020-06-20 15:04:49" itemprop="dateCreated datePublished" datetime="2020-06-20T15:04:49+09:00">2020-06-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Updated at: 2020-07-17 03:28:42" itemprop="dateModified" datetime="2020-07-17T03:28:42+09:00">2020-07-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-learning-in-Julia/" itemprop="url" rel="index">
                    <span itemprop="name">Deep learning in Julia</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>해당 시리즈는 프로그래밍 언어 중 하나인 줄리아(Julia)로 딥러닝(Deep learning)을 구현하면서 원리를 설명합니다.<br><a id="more"></a></p>
<hr>
<p>지금까지 우리는 다층퍼셉트론(MLP) 기반의 완전연결신경망(Fully Connected network)을 구현하면서 원리를 알아보았다. 하지만 이미지 데이터를 기반으로 신경망을 구현할 때, 완전연결신경망은 이미지 데이터를 일자로 펴서 학습하므로 데이터의 공간적 특성을 이해하기 어렵다. 이를 해결하기 위해 등장한 개념이 바로 합성곱(convolution)이다.</p>
<h2 id="CNN-Convolutional-Neural-Network-이란"><a href="#CNN-Convolutional-Neural-Network-이란" class="headerlink" title="CNN (Convolutional Neural Network) 이란"></a>CNN (Convolutional Neural Network) 이란</h2><p>‘합성곱 신경망(CNN, Convolutional Neural Network)’은 3차원의 이미지 데이터를 그대로 입력받아 학습하는 신경망이다. 완전연결신경망과 다른 점은 ‘합성곱(convolution)’과 ‘풀링(pooling)’이라는 레이어가 추가된다는 것이다. 따라서 CNN을 이해하기 위해서는 두 레이어의 원리를 알아야 한다.</p>
<h2 id="합성곱-Convolution"><a href="#합성곱-Convolution" class="headerlink" title="합성곱 (Convolution)"></a>합성곱 (Convolution)</h2><p>합성곱은 하나의 이미지를 여러 조각으로 나누어 각 조각의 특성을 전달하는 방식이다. 아래의 그림은 합성곱의 원리를 보여준다. 참고로 <a href="https://github.com/Hyeonji-Ryu/Machine_Learning_in_Julia/blob/master/CNN/layers_without_im2col.jl" target="_blank" rel="noopener">깃허브</a>에서 줄리아로 구현한 합성곱 코드를 볼 수 있다.</p>
<p><img src="/images/65.png" alt="합성곱"></p>
<p>먼저 그림에서 <code>Input_data</code>는 입력된 이미지이고, <code>Filter_1</code> 와 <code>Filter_2</code>는 가중치이다. 합성곱층에서는 가중치 크기에 맞게 조각난 입력데이터들을 곱하여 합한 후 결과값 요소로 반환한다. 위의 예시는 다음과 같은 셋팅이다.</p>
<ul>
<li><p>입력데이터: $5 \times 5 \times 1 \times 1$ 배열인 4차원 데이터이다.<br>기본적으로 이미지 데이터는 3차원으로 구성되어 있지만, 보통 배치데이터로 훈련하기 때문에 4차원이라고 보는 것이 더 좋다. 줄리아에서 배열의 순서는 <strong>행 $\times$ 열 $\times$ 색(차원) $\times$ 개수</strong> 이다. 여기서 <strong>색(차원)</strong>은 흑백인 경우 <code>1</code>, 컬러인 경우 RGB로 나뉘어 <code>3</code>이 된다.</p>
</li>
<li><p>가중치(필터): $3 \times 3 \times 1 \times 2$ 배열인 4차원 데이터이다.<br>가중치는 입력데이터와 곱해진다. 가중치의 배열 순서는 <strong>행 $\times$ 열 $\times$ 색(차원) $\times$ 개수</strong>으로 입력데이터와 동일하다. 참고로 가중치의 개수는 결과값의 차원이 된다.</p>
</li>
</ul>
<p>입력데이터의 조각들과 가중치를 각각 곱한 후 그 곱들의 합이 결과값의 원소가 된다. 이미지를 조각내는 기준을 스트라이드(stride)라고 하며, 위의 예시는 스트라이드가 1인 경우이다.<br>또한 합성곱은 입력데이터보다 더 작은 크기의 결과를 반환한다. 결과값 행렬의 크기를 구하는 식은 다음과 같다.</p>
<script type="math/tex; mode=display">\frac{input\ size + 2*padding - filter\ size}{stride} +  1</script><p>위 식을 따라 위의 그림 예시의 값들을 넣어본다면 다음과 같다.</p>
<script type="math/tex; mode=display">\frac{5 + 0 - 3}{1} + 1 = 3</script><p>참고로 $padding$은 데이터 크기가 줄어드는 것을 막기 위해서 사용하는 방법이다.</p>
<p><strong>Note</strong><br>패딩 (padding) 이란?<br>패딩은 데이터에 표면에 0을 둘러서 데이터 크기를 키우는 기술을 의미한다. 예를 들어 $2 \times 2$ 행렬이 있고 패딩을 1 추가한다면, 모든 표면에 0이 둘러지면서 $4 \times 4$ 행렬을 반환한다.</p>
<p>결국 입력데이터 $5 \times 5 \times 1 \times 1$ 배열은 가중치 $3 \times 3 \times 1 \times 2$ 배열과 합성곱되어 결과값 $3 \times 3 \times 2 \times 1$ 배열을 도출한다. 이를 모두 정리하면 다음과 같다.</p>
<ul>
<li>입력데이터 형상: $5 \times 5 \times 1 \times 1$</li>
<li>필터 형상: $3 \times 3 \times 1 \times 2$</li>
<li>합성곱 결과 형상: $3 \times 3 \times 2 \times 1$</li>
</ul>
<p>합성곱 결과의 배열 순서는 <strong>행 $\times$ 열 $\times$ 가중치 개수 $\times$ 입력값 개수</strong>이다. 즉, 가중치의 개수가 결과값의 차원이 되는 것이다.</p>
<h2 id="풀링-pooling"><a href="#풀링-pooling" class="headerlink" title="풀링 (pooling)"></a>풀링 (pooling)</h2><p>풀링은 데이터의 크기를 줄여주는 방법이다. 데이터가 큰 경우 파라미터가 기하급수적으로 증가하여 연산 시간이 많이 소요된다. 이를 방지하고자 중간에 풀링 계층을 넣어 데이터의 크기를 줄여준다. 풀링은 크게 ‘최대값 풀링(Max pooling)’과 ‘평균 풀링(Average pooling)’이 있다. 보통 최대값 풀링이 많이 사용된다. <a href="https://github.com/Hyeonji-Ryu/Machine_Learning_in_Julia/blob/master/CNN/layers_without_im2col.jl" target="_blank" rel="noopener">깃허브</a>에서 줄리아로 구현한 풀링 코드를 볼 수 있다.</p>
<h3 id="최대값-풀링-Max-pooling"><a href="#최대값-풀링-Max-pooling" class="headerlink" title="최대값 풀링 (Max pooling)"></a>최대값 풀링 (Max pooling)</h3><p>최대값 풀링의 원리를 그림으로 나타내면 다음과 같다.</p>
<p><img src="/images/66.png" alt="최대 풀링"></p>
<p>풀링에서는 합성곱과 달리 필터가 필요하지 않다. 다만, 풀링의 범위를 정해야 한다. 위의 그림에서는 $2 \times 2$ 크기로 풀링을 진행하며, 해당 범위에서 최대값을 반환하는 것이 최대값 풀링이다.</p>
<h3 id="평균-풀링-Average-pooling"><a href="#평균-풀링-Average-pooling" class="headerlink" title="평균 풀링 (Average pooling)"></a>평균 풀링 (Average pooling)</h3><p>평균 풀링은 풀링 크기의 요소들의 평균을 결과값으로 반환한다. 그림으로는 다음과 같다.</p>
<p><img src="/images/67.png" alt="평균 풀링"></p>
<h2 id="Simple-CNN-구현"><a href="#Simple-CNN-구현" class="headerlink" title="Simple CNN 구현"></a>Simple CNN 구현</h2><p>지금까지 합성곱층과 풀링층의 원리에 대해서 알아보았다. 이제 실제 코드로 구현하여 신경망을 학습해보자.</p>
<h3 id="준비-단계"><a href="#준비-단계" class="headerlink" title="준비 단계"></a>준비 단계</h3><p>먼저 <a href="https://github.com/Hyeonji-Ryu/Machine_Learning_in_Julia" target="_blank" rel="noopener">깃허브</a>에 들어가서 해당 <code>clone</code>이나 <code>Download zip</code>을 하여 코드들을 저장해야 한다.<br>만약 이에 대해 잘 모르거나 어려운 사람들은 <a href="https://github.com/Hyeonji-Ryu/Machine_Learning_in_Julia/tree/master/CNN" target="_blank" rel="noopener">해당 페이지</a>에서 코드를 직접 복사해서 입력할 수도 있다.</p>
<p>깃허브 데스크탑에 코드를 클론하거나 저장한 분들은 현재 사용하고 있는 커맨드의 경로를 <code>CNN</code> 파일로 변경해야 한다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pwd <span class="comment"># 현재 경로 확인</span></span><br><span class="line">cd 코드가 있는 파일 경로 입력/Machine_Learning_in_Julia/CNN</span><br></pre></td></tr></table></figure>
<p>다시 <code>pwd</code>를 입력했을 때 아래와 같이 변경되어 있으면 변경이 완료된 것이다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/Users/코드가 있는 파일 경로/Machine_Learning_in_Julia/CNN</span><br></pre></td></tr></table></figure>
<p>변경이 완료된 후 아래의 코드를 입력하자.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">include(<span class="string">"MNIST_data.jl"</span>)</span><br><span class="line">include(<span class="string">"functions.jl"</span>)</span><br><span class="line">include(<span class="string">"layers_without_im2col.jl"</span>)</span><br><span class="line">include(<span class="string">"making_network.jl"</span>)</span><br><span class="line">include(<span class="string">"optimizers.jl"</span>)</span><br></pre></td></tr></table></figure>
<p>위 코드는 파일에 들어 있는 모든 코드들을 작동시킨다. 만약 코드를 복사하여 사용할 분들은 <a href="https://github.com/Hyeonji-Ryu/Machine_Learning_in_Julia/tree/master/CNN" target="_blank" rel="noopener">해당 페이지</a>에서 위의 파일들의 코드를 복사하여 입력해주면 된다.</p>
<p>이제 간단한 CNN 모델을 만들 준비가 끝났다.</p>
<h3 id="모델-설계"><a href="#모델-설계" class="headerlink" title="모델 설계"></a>모델 설계</h3><p>합성곱 신경망 1층과 완견연결 신경망 2층을 사용하여 모델을 구성하고자 한다. 모델의 순서는 다음과 같다.</p>
<p><img src="/images/68.png" alt="simple CNN"></p>
<p>위 모델은 책 ‘밑바닥부터 시작하는 딥러닝’에서 예제로 사용한 것이다. 매우 간단하지만 <code>MNIST</code> 데이터를 학습하는 데 문제가 없다. 이제 모델 층에 알맞은 <code>predict()</code>를 정의해야 한다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">function</span>  predict(input)</span><br><span class="line"></span><br><span class="line">    pconv_1 = conv2D_forward_batch(pre_dense, input, params[<span class="string">"W1"</span>], params[<span class="string">"b1"</span>],<span class="number">1</span>)</span><br><span class="line">    pconv_Re = relu.(pconv_1)</span><br><span class="line">    ppool_1 = maxpooling2D_forward_batch(pre_pool,pconv_Re, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    flatten_1 = flatten_forward_batch(pre_flatten,ppool_1)</span><br><span class="line">    dense_1 = (flatten_1 * params[<span class="string">"W2"</span>]) .+ params[<span class="string">"b2"</span>]</span><br><span class="line">    dense_relu = relu.(dense_1)</span><br><span class="line">    dense_2 = (dense_relu * params[<span class="string">"W3"</span>]) .+ params[<span class="string">"b3"</span>]</span><br><span class="line">    result = softmax(dense_2)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h3 id="학습-구현"><a href="#학습-구현" class="headerlink" title="학습 구현"></a>학습 구현</h3><p><code>loss()</code>에 사용되는 예측 함수를 설정한 후에 파라미터인 가중치와 편향 초기값도 설정한다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">W =[<span class="string">"W1"</span>,<span class="string">"W2"</span>,<span class="string">"W3"</span>]</span><br><span class="line">b = [<span class="string">"b1"</span>,<span class="string">"b2"</span>,<span class="string">"b3"</span>]</span><br><span class="line">weight_size = [(<span class="number">5</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">30</span>),(<span class="number">4320</span>,<span class="number">100</span>),(<span class="number">100</span>,<span class="number">10</span>)];</span><br><span class="line">input_size = (<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">params = making_network(W, b, weight_size,input_size,<span class="string">"std"</span>);</span><br></pre></td></tr></table></figure>
<p>초기값은 기본값으로 사용하는 <code>std</code>로 설정하였다. 초기값에 대해서는 <a href="https://hyeonji-ryu.github.io/2020/05/15/Deeplearning-12/#more">인공신경망 최적화 - 가충치 초기값</a>에서 더 자세히 알 수 있다.</p>
<p>파라미터를 만들었다면, 이제 모델에서 필요한 값들을 저장할 저장소를 생성한다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># predict()용 저장소</span></span><br><span class="line">pre_dense = dense_layer(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">pre_pool= repository(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">pre_flatten = repository(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 실제 저장소</span></span><br><span class="line">result = SoftmaxwithLoss(<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">dense1 = dense_layer(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">dense2 = dense_layer(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">dense3 = dense_layer(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">Relu1 = repository(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">Relu2 = repository(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">optimizer = optimizers(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">pool1= repository(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">flatten1 = repository(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><code>pre</code>라고 붙은 저장소는 모델에 사용되는 함수의 파라미터 개수를 맞춰주기 위해 만든 것이다. 사실상 모델에 필요한 값을 저장하는 저장소는 아니다. 다음으로는 로스값과 미분값을 저장할 리스트와 딕셔너리를 정의한다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grads = <span class="built_in">Dict</span>()</span><br><span class="line">train_loss_list= []</span><br></pre></td></tr></table></figure>
<p>이제 모델을 작동시켜보자. 해당 모델의 구성은 다음과 같다.</p>
<ul>
<li>Algorithm: backpropagation</li>
<li>Optimizer: Adam</li>
<li>batch_size: 100</li>
<li>one_epoch: 600</li>
</ul>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@time</span> <span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:<span class="number">600</span></span><br><span class="line"></span><br><span class="line">        batch_size = rand(<span class="number">1</span>:size(train_x)[<span class="number">4</span>],<span class="number">100</span>)</span><br><span class="line">        train_x_batch = train_x[:,:,:,batch_size]</span><br><span class="line">        t_batch = reshape(t[batch_size,:],<span class="number">100</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#신경망 계산</span></span><br><span class="line">        conv_1 = conv2D_forward_batch(dense1,train_x_batch,params[<span class="string">"W1"</span>],params[<span class="string">"b1"</span>],<span class="number">1</span>)</span><br><span class="line">        conv_Re = relu_forward(Relu1, conv_1)</span><br><span class="line">        pool_1 = maxpooling2D_forward_batch(pool1, conv_Re, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        flatten_1 = flatten_forward_batch(flatten1, pool_1)</span><br><span class="line">        dense_1 = dense_layer_forward(dense2,flatten_1,params[<span class="string">"W2"</span>],params[<span class="string">"b2"</span>])</span><br><span class="line">        dense_relu = relu_forward(Relu2, dense_1)</span><br><span class="line">        dense_2 = dense_layer_forward(dense3,dense_relu,params[<span class="string">"W3"</span>],params[<span class="string">"b3"</span>])</span><br><span class="line">        num = SoftmaxwithLoss_forward(dense_2,t_batch)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#역전파 알고리즘</span></span><br><span class="line">        last_layer = SoftmaxwithLoss_backward(result)</span><br><span class="line">        dense_2_back = dense_layer_backward(dense3, last_layer)</span><br><span class="line">        grads[<span class="string">"W3"</span>] = dense3.dw</span><br><span class="line">        grads[<span class="string">"b3"</span>] = dense3.db</span><br><span class="line">        dense_relu_back = relu_backward(Relu2, dense_2_back)</span><br><span class="line">        dense_1_back = dense_layer_backward(dense2, dense_relu_back)</span><br><span class="line">        grads[<span class="string">"W2"</span>] = dense2.dw</span><br><span class="line">        grads[<span class="string">"b2"</span>] = dense2.db</span><br><span class="line">        flatten_1_back = flatten_backward_batch(flatten1,dense_1_back)</span><br><span class="line">        pool_1_back = maxpooling2D_backward_batch(pool1, flatten_1_back, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        conv_Re_back = relu_backward(Relu1, pool_1_back)</span><br><span class="line">        conv_back = conv2D_backward_batch(dense1,conv_Re_back)</span><br><span class="line">        grads[<span class="string">"W1"</span>] = dense1.dw</span><br><span class="line">        grads[<span class="string">"b1"</span>] = dense1.db</span><br><span class="line"></span><br><span class="line">        <span class="comment">#가중치 갱신</span></span><br><span class="line">        Adam(params,grads)</span><br><span class="line"></span><br><span class="line">        temp_loss = loss_CNN_batch(train_x_batch,t_batch)</span><br><span class="line">        print(<span class="string">"NO.<span class="variable">$i</span>: "</span>)</span><br><span class="line">        println(temp_loss)</span><br><span class="line">        append!(train_loss_list, temp_loss)</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>위 모델의 정확도는 다음과 같다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1에폭: 96.8</span></span><br><span class="line"><span class="comment"># 2에폭: 97.73</span></span><br><span class="line"><span class="comment"># 3에폭: 98.35</span></span><br><span class="line"><span class="comment"># 4에폭: 98.39</span></span><br><span class="line"><span class="comment"># 5에폭: 98.50999999999999</span></span><br></pre></td></tr></table></figure>
<p>확실히 MLP보다 학습이 잘 된다는 것을 확인할 수 있다.</p>
<h2 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h2><p>위 코드는 1에폭(600)에 1시간 정도 소요된다. 이전까지 배웠던 MLP 모델을 작동시켜봤다면 ‘이 모델이 역전파를 사용한 것이 맞는가?’ 라는 의문이 들 수 있다.<br>사실 위 모델에 사용된 방식의 합성곱층과 풀링층은 이론적으로는 맞지만, 아무도 사용하지 않는다. 그 이유는 너무 느려서이다. 4차원 데이터를 가공하지 않고 인덱스를 잡아 함수를 실행하는 것은 컴퓨터의 입장에서 엄청난 노동이다. 그래서 우리는 기술적으로 4차원 데이터를 2차원으로 변환한 뒤, 계산을 하고 다시 4차원으로 조립하는 과정을 사용한다.<br>이 방법은 아~~주 느린 합성곱층과 풀링층을 훨씬 빠르게 작동하게 만들어준다.</p>
<p>만약 위 코드를 1에폭이라도 돌려봤다면 그 필요성을 실감할 것이기에, 한 번쯤 돌려보기를 권장한다. 앞서 설명했던 차원을 변경해주는 함수는 일반적으로 동일한 이름으로 쓰인다. 순방향에서는 <code>im2col()</code>, 역방향에서는 <code>col2im()</code>이다. 의미는 이미지에서 행렬로, 또 행렬에서 이미지로 변경해준다는 의미이다. 즉, 4차원 데이터를 2차원으로, 2차원 데이터를 4차원으로 변경해준다는 의미와 동일하다.</p>
<p>다음 글에서는 <code>im2col()</code>과  <code>col2im()</code>의 원리를 설명하고, 줄리아로 구현해볼 것이다. 또한 이를 바탕으로 합성곱층과 풀링층의 함수를 구현할 것이다.</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/" rel="tag"># 딥러닝</a>
              <a href="/tags/Deeplearning/" rel="tag"># Deeplearning</a>
              <a href="/tags/%EC%A4%84%EB%A6%AC%EC%95%84/" rel="tag"># 줄리아</a>
              <a href="/tags/CNN/" rel="tag"># CNN</a>
              <a href="/tags/%ED%95%A9%EC%84%B1%EA%B3%B1/" rel="tag"># 합성곱</a>
              <a href="/tags/%EC%9D%B4%EB%AF%B8%EC%A7%80%EC%8B%A0%EA%B2%BD%EB%A7%9D/" rel="tag"># 이미지신경망</a>
              <a href="/tags/%ED%92%80%EB%A7%81/" rel="tag"># 풀링</a>
              <a href="/tags/Julia/" rel="tag"># Julia</a>
              <a href="/tags/%EB%AA%A8%EB%8D%B8/" rel="tag"># 모델</a>
              <a href="/tags/flatten/" rel="tag"># flatten</a>
              <a href="/tags/convolution/" rel="tag"># convolution</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/06/14/Deeplearning-13/" rel="prev" title="13. 인공신경망 최적화 - 드랍아웃(Dropout)">
      <i class="fa fa-chevron-left"></i> 13. 인공신경망 최적화 - 드랍아웃(Dropout)
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/06/26/Deeplearning-15/" rel="next" title="15. im2col의 원리">
      15. im2col의 원리 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          목차
        </li>
        <li class="sidebar-nav-overview">
          훑어보기
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#CNN-Convolutional-Neural-Network-이란"><span class="nav-number">1.</span> <span class="nav-text">CNN (Convolutional Neural Network) 이란</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#합성곱-Convolution"><span class="nav-number">2.</span> <span class="nav-text">합성곱 (Convolution)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#풀링-pooling"><span class="nav-number">3.</span> <span class="nav-text">풀링 (pooling)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#최대값-풀링-Max-pooling"><span class="nav-number">3.1.</span> <span class="nav-text">최대값 풀링 (Max pooling)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#평균-풀링-Average-pooling"><span class="nav-number">3.2.</span> <span class="nav-text">평균 풀링 (Average pooling)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Simple-CNN-구현"><span class="nav-number">4.</span> <span class="nav-text">Simple CNN 구현</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#준비-단계"><span class="nav-number">4.1.</span> <span class="nav-text">준비 단계</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#모델-설계"><span class="nav-number">4.2.</span> <span class="nav-text">모델 설계</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#학습-구현"><span class="nav-number">4.3.</span> <span class="nav-text">학습 구현</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#결론"><span class="nav-number">5.</span> <span class="nav-text">결론</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Hyeonji Ryu</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">52</span>
          <span class="site-state-item-name">포스트</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">카테고리</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">83</span>
        <span class="site-state-item-name">태그</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hyeonji Ryu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.1
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
